<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://utndatasystems.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://utndatasystems.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-23T10:03:23+00:00</updated><id>https://utndatasystems.github.io/feed.xml</id><title type="html">UTN Data Systems</title><subtitle></subtitle><entry><title type="html">Democratizing Data Science</title><link href="https://utndatasystems.github.io/blog/2026/dataloom/" rel="alternate" type="text/html" title="Democratizing Data Science"/><published>2026-01-16T00:00:00+00:00</published><updated>2026-01-16T00:00:00+00:00</updated><id>https://utndatasystems.github.io/blog/2026/dataloom</id><content type="html" xml:base="https://utndatasystems.github.io/blog/2026/dataloom/"><![CDATA[<p>The database community often focuses on improving the performance of database systems, which is (and always will be) of critical importance. This continues to drive innovation by unlocking ever larger datasets, challenging workloads, and near-instantaneous results. Yet, people outside the database community struggle to harness the treasure trove of modern database systems: It takes hours and expert knowledge to set up, load, and run workloads; thus wasting time and delaying insights. Therefore, the database community has started widening its focus, as highlighted in a recent industry perspective:</p> <blockquote> <p><em>“The important feature of a database is how quickly you can go from idea to answer, not query to result.”</em> – January, 2024, MotherDuck, <strong>Jordan Tigani</strong></p> </blockquote> <p>and at last year’s SIGMOD panel discussion:</p> <blockquote> <p><em>“We are asking the world to bring their data into our format. We need to work on the entire data science pipeline!”</em> – June, 2025, SIGMOD Berlin, <strong>Sihem Amer-Yahia</strong></p> </blockquote> <p>In this article, we explore why this new frontier matters and present Dataloom, our research prototype designed to help open the black box of data systems to a broader audience.</p> <h2 id="new-metrics-time-to-insight-and-accessibility">New Metrics: Time-To-Insight and Accessibility</h2> <p>The task of a data scientist is to answer questions based on data. Given a dataset, this involves many steps before an answer can be formulated: understanding the data, loading it, cleaning it, writing queries, visualizing results, and usually many iterations in each step. Sharply put, a database that processes terabytes in milliseconds is useless to a user who cannot figure out how to load their data into it. In more technical terms, we can consider <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s law</a>: If it takes an hour to understand, load, and clean data, the benefit of speeding up the runtime of a 1-second query by 10x is rather limited. In these interactive scenarios, <strong>time-to-insight</strong> (i.e., finding an answer to a particular question) is critical. Improving this process enables users to answer questions while they are still relevant and allows shifting employee cycles from tedious tasks to the interesting and fun parts of data science.</p> <p>At the same time, working with data is becoming omnipresent in professional as well as personal life. Sticking with well-known metaphors: Data shares not only the value of oil but also its fluid nature, seeping into all domains and across skill levels. Nowadays, most aspects of an organization (controlling, reporting, monitoring, and research) heavily rely on data. Even individually, people track finances, health, fitness, and more. In both settings, an increasing number of people, especially non-experts, want to work with data. Improving the ease-of-use of well-studied, schema-rich, and scalable data processing systems (i.e., database systems) can thus benefit a broad spectrum of people (even veteran data scientists know how much time is spent wrangling with formats or missing values).</p> <p>TL;DR: time-to-insight is an important metric for more and more people.</p> <h2 id="case-study-data-engineering-class-of-2023">Case Study: Data Engineering Class of 2023</h2> <p>Our Master’s students at <a href="https://www.utn.de/en/">UTN</a> have a data engineering class where they learn to build scalable data pipelines. As part of their final project, we ran TPC-H in <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a> and gave them a dump of all log files in CSV format. Their task was to figure out which workload we ran and prepare a dashboard with their analysis.</p> <p>The first major hurdle for the students was loading the dataset into an analytical database. They had to figure out which CSV files belonged to which table, infer the schema and column names, create the SQL <code class="language-plaintext highlighter-rouge">create table</code> statements, and then load the data into the system. The result: Lots of frustration, copious amounts of “uninspired” boilerplate code for loading, and delayed results.</p> <h2 id="enter-dataloom">Enter: Dataloom</h2> <p>On the very same day, we hacked together the first version of Dataloom: A simple prototype that—in its earliest form—combined LLMs and classical algorithms (e.g., CSV parsing, type inference, etc.) to make the loading process seamless and fast. <em>How did it do this?</em> Given a chaotic set of files, we use an LLM to figure out which files belong to which table, how to name columns, and create a natural language description of the table—all tasks that used to require human intervention, as traditional algorithms are very bad at this. We then ran some classical schema detection algorithms and loaded everything into <a href="https://duckdb.org/">DuckDB</a>. Thus we transformed an hour-long process that stood between students and their weekend into a quick and easy-to-use tool … that worked 80% of the time ;).</p> <p>Building Dataloom, we quickly realized that LLMs can be unpredictable at times and don’t always churn out the correct results in the intended way. However, we were not daunted but instead inspired to make Dataloom into a system that allows users easy access to data analytics. Initially, we focused on the schema mapping and refinement issue, which we presented in a <a href="https://www.vldb.org/pvldb/vol17/p4449-renen.pdf">demo paper at VLDB 2024</a>, which sparked much interest in the attendees. Over the previous year, Dataloom has expanded in its scope from just loading data to cleaning, visualizing, and reporting results—thus encapsulating more and more data science tasks.</p> <p>Our vision is to build an end-to-end agentic data platform, enabling domain experts to acquire, clean, analyze, and visualize data in a principled manner by combining the benefits of LLMs with decades of database research.</p> <p>Stay tuned for more posts on our <a href="https://utndatasystems.github.io/data-loom/">Dataloom website</a>: “Future (agentic) data is not doomed, it will be loomed.”</p>]]></content><author><name>&lt;a href=&quot;https://dblp.org/pid/219/9679.html&quot;&gt;Alexander van Renen&lt;/a&gt; and &lt;a href=&quot;https://scholar.google.de/citations?user=y3IdRusAAAAJ&amp;hl=en&quot;&gt;Andreas Kipf&lt;/a&gt;</name></author><summary type="html"><![CDATA[Our vision is to build an end-to-end agentic data platform, enabling domain experts to acquire, clean, analyze, and visualize data in a principled manner by combining the benefits of LLMs with decades of database research.]]></summary></entry><entry><title type="html">Launching Our Blog And Wrapping Up 2025</title><link href="https://utndatasystems.github.io/blog/2025/recap/" rel="alternate" type="text/html" title="Launching Our Blog And Wrapping Up 2025"/><published>2025-12-31T00:00:00+00:00</published><updated>2025-12-31T00:00:00+00:00</updated><id>https://utndatasystems.github.io/blog/2025/recap</id><content type="html" xml:base="https://utndatasystems.github.io/blog/2025/recap/"><![CDATA[<p>I’m super excited to launch our blog! We’ll use this space to share what’s happening in our lab, from research papers and systems to the day-to-day life of our team. To kick things off, let’s look back at 2025.</p> <h2 id="award-winning-research">Award-Winning Research</h2> <p>We were super happy to see our work recognized by the community this year!</p> <ul> <li><strong>SIGMOD 2025 Honorable Mention</strong>: Our paper <a href="https://arxiv.org/pdf/2409.08013">“DPconv: Super-Polynomially Faster Join Ordering”</a> by Mihail Stoian and Andreas Kipf received an Honorable Mention at SIGMOD 2025 in Berlin.</li> <li><strong>EDBT 2025 Best Demo Award</strong>: We were also thrilled to pick up a <strong>Best Demo Award</strong> at EDBT 2025 in Barcelona for <a href="https://utndatasystems.github.io/virtual/">“Virtual: Compressing Data Lake Files”</a>.</li> </ul> <h2 id="collaborations">Collaborations</h2> <p>Research in data systems doesn’t happen in an ivory tower. We love working closely with industry leaders and top academic labs to solve real-world problems.</p> <ul> <li><strong>SIGMOD 2025 Industrial</strong>: We presented <a href="https://snowflakepruning.github.io/">“Pruning in Snowflake: Working Smarter, Not Harder”</a> in collaboration with Snowflake, where we explored some cool new pruning techniques.</li> <li><strong>Google BigQuery &amp; SemBench</strong>: Our work on <a href="https://sembench.ngrok.io/"><strong>SemBench</strong></a>, a benchmark for semantic query processing engines, is a huge team effort with Google BigQuery, Cornell, TU Berlin, University of Michigan, MIT CSAIL, and Vrije Universiteit Amsterdam.</li> </ul> <h2 id="a-benchmark-heavy-year">A Benchmark-Heavy Year</h2> <p>Benchmarks are the foundation of systems research. While we’ve been involved in benchmarking for a while (you might know our past work on <a href="https://arxiv.org/pdf/1809.00677"><strong>JOB-light</strong></a>, <a href="https://github.com/learnedsystems/SOSD"><strong>SOSD</strong></a>, and <a href="https://github.com/amazon-science/redset"><strong>Redset</strong></a>), we’ve ramped up our efforts in 2025:</p> <ul> <li><a href="https://arxiv.org/pdf/2506.12488"><strong>Redbench</strong></a>: We presented it at aiDM 2025, and we’re continuing to develop this workload synthesis work in collaboration with <strong>TU Darmstadt</strong>.</li> <li><a href="http://sembench.org/"><strong>SemBench</strong></a>: Our new benchmark, designed specifically for evaluating semantic SQL operators.</li> </ul> <h2 id="community-building-and-interdisciplinary-research">Community Building and Interdisciplinary Research</h2> <p>Beyond the core research, we’ve been connecting with the broader community:</p> <ul> <li><strong>Bavarian Database Day</strong>: We’re proud to have organized the very first <a href="https://databaseday.de/"><strong>Bavarian Database Day</strong></a>, which brought together researchers and practitioners from Bavaria and beyond.</li> <li><strong>Podcast Feature</strong>: Mihail Stoian hopped on the <strong>Disseminate podcast</strong> to talk about our work on robust query execution in the <a href="https://www.youtube.com/watch?v=HfZuVtY5lZg"><strong>episode on Parachute</strong></a>.</li> <li><strong>UTN Internal Milestone</strong>: We even published a first <a href="https://arxiv.org/abs/2507.10391"><strong>cross-department workshop paper</strong></a>, which was a big step for interdisciplinary research here at UTN.</li> </ul> <h2 id="everything-else">Everything Else!</h2> <p>It wouldn’t be a proper recap without mentioning all the other cool stuff we did:</p> <ul> <li><strong>BTW 2025</strong>: I was co-organizing the <a href="https://luthramanisha.github.io/ML4Sys-and-Sys4ML/"><strong>ML4Sys and Sys4ML workshop</strong></a> at BTW 2025, and I also gave a talk about <a href="https://itu-dasyalab.github.io/btw2025workshop/">“Workload-Driven Indexing in the Cloud”</a>.</li> <li><strong>Dagstuhl Seminar</strong>: I attended a very cool Dagstuhl seminar on <a href="https://www.dagstuhl.de/seminars/seminar-calendar/seminar-details/25182"><strong>Table Representation Learning</strong></a>, which is actually where we first kicked off our work on SemBench.</li> <li><strong>Lab Offsite</strong>: We had a nice summer offsite south of Nuremberg. Between working on <strong>ML-based data compression</strong>, we managed to squeeze in some fun swimming and wakeboarding at the nearby lake.</li> <li><strong>VLDB Presentations</strong>: We were also busy in London at VLDB. We presented <a href="https://arxiv.org/abs/2507.10391">“Instance-Optimized String Fingerprints”</a> at AIDB and <a href="https://www.arxiv.org/pdf/2506.13670"><strong>Parachute</strong></a> at the main Research Track.</li> <li><strong>Long Night of Sciences</strong>: We presented our agentic data analytics platform <a href="https://utndatasystems.github.io/data-loom/"><strong>DataLoom</strong></a> and our data lake file format <a href="https://utndatasystems.github.io/virtual/"><strong>Virtual</strong></a> at the <a href="https://nacht-der-wissenschaften.de/"><strong>Long Night of Sciences</strong></a>.</li> </ul> <p>All in all, it’s been a crazy year, and I couldn’t be more proud of what we’ve achieved. I’m super excited for what 2026 has in store. Stay tuned!</p>]]></content><author><name>&lt;a href=&quot;https://scholar.google.de/citations?user=y3IdRusAAAAJ&amp;hl=en&quot;&gt;Andreas Kipf&lt;/a&gt;</name></author><summary type="html"><![CDATA[I'm super excited to launch our blog! We'll use this space to share what's happening in our lab, from research papers and systems to the day-to-day life of our team. To kick things off, let's look back at 2025.]]></summary></entry></feed>